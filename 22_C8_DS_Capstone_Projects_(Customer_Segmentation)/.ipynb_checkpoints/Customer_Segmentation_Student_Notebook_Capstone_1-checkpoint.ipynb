{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yG6Ti6UOiqav"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2v-2JDuiqa0"
   },
   "source": [
    "# WELCOME!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLS5y2Jqiqa1"
   },
   "source": [
    "Welcome to \"RFM Customer Segmentation & Cohort Analysis Project\". This is the first project of the Capstone Project Series, which consists of 4 different project that contain different scenarios.\n",
    "\n",
    "This is a project which you will learn what is RFM? And how to apply RFM Analysis and Customer Segmentation using K-Means Clustering. Also you will improve your Data Cleaning, Data Visualization and Exploratory Data Analysis capabilities. On the other hand you will create Cohort and Conduct Cohort Analysis. \n",
    "\n",
    "Before diving into the project, please take a look at the determines and project structure.\n",
    "\n",
    "- **NOTE:** This tutorial assumes that you already know the basics of coding in Python and are familiar with the theory behind K-Means Clustering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SCOFEfqiqa1"
   },
   "source": [
    "# #Determines\n",
    "\n",
    "Using the [Online Retail dataset](https://archive.ics.uci.edu/ml/datasets/Online+Retail) from the UCI Machine Learning Repository for exploratory data analysis, ***Customer Segmentation***, ***RFM Analysis***, ***K-Means Clustering*** and ***Cohort Analysis***.\n",
    "\n",
    "This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail. The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n",
    "\n",
    "Feature Information:\n",
    "\n",
    "**InvoiceNo**: Invoice number. *Nominal*, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation. \n",
    "<br>\n",
    "**StockCode**: Product (item) code. *Nominal*, a 5-digit integral number uniquely assigned to each distinct product.\n",
    "<br>\n",
    "**Description**: Product (item) name. *Nominal*. \n",
    "<br>\n",
    "**Quantity**: The quantities of each product (item) per transaction. *Numeric*.\n",
    "<br>\n",
    "**InvoiceDate**: Invoice Date and time. *Numeric*, the day and time when each transaction was generated.\n",
    "<br>\n",
    "**UnitPrice**: Unit price. *Numeric*, Product price per unit in sterling.\n",
    "<br>\n",
    "**CustomerID**: Customer number. *Nominal*, a 5-digit integral number uniquely assigned to each customer.\n",
    "<br>\n",
    "**Country**: Country name. *Nominal*, the name of the country where each customer resides.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "First of all, to observe the structure of the data and missing values, you can use exploratory data analysis and data visualization techniques.\n",
    "\n",
    "You must do descriptive analysis. Because you must understand the relationship of the features to each other and clear the noise and missing values in the data. After that, the data set will be ready for RFM analysis.\n",
    "\n",
    "Before starting the RFM Analysis, you will be asked to do some analysis regarding the distribution of *Orders*, *Customers* and *Countries*. These analyzes will help the company develop its sales policies and contribute to the correct use of resources.\n",
    "\n",
    "You will notice that the UK not only has the most sales revenue, but also the most customers. So you will continue to analyze only UK transactions in the next RFM Analysis, Customer Segmentation and K-Means Clustering topics.\n",
    "\n",
    "Next, you will begin RFM Analysis, a customer segmentation technique based on customers' past purchasing behavior. \n",
    "\n",
    "By using RFM Analysis, you can enable companies to develop different approaches to different customer segments so that they can get to know their customers better, observe trends better, and increase customer retention and sales revenues.\n",
    "\n",
    "You will calculate the Recency, Frequency and Monetary values of the customers in the RFM Analysis you will make using the data consisting of UK transactions. Ultimately, you have to create an RFM table containing these values.\n",
    "\n",
    "In the Customer Segmentation section, you will create an RFM Segmentation Table where you segment your customers by using the RFM table. For example, you can label the best customer as \"Big Spenders\" and the lost customer as \"Lost Customer\".\n",
    "\n",
    "We will segment the customers ourselves based on their recency, frequency, and monetary values. But can an **unsupervised learning** model do this better for us? You will use the K-Means algorithm to find the answer to this question. Then you will compare the classification made by the algorithm with the classification you have made yourself.\n",
    "\n",
    "Before applying K-Means Clustering, you should do data pre-processing. In this context, it will be useful to examine feature correlations and distributions. In addition, the data you apply for K-Means should be normalized.\n",
    "\n",
    "On the other hand, you should inform the K-means algorithm about the number of clusters it will predict. You will also try the *** Elbow method *** and *** Silhouette Analysis *** to find the optimum number of clusters.\n",
    "\n",
    "After the above operations, you will have made cluster estimation with K-Means. You should visualize the cluster distribution by using a scatter plot. You can observe the properties of the resulting clusters with the help of the boxplot. Thus you will be able to tag clusters and interpret results.\n",
    "\n",
    "Finally, you will do Cohort Analysis with the data you used at the beginning, regardless of the analysis you have done before. Cohort analysis is a subset of behavioral analytics that takes the user data and breaks them into related groups for analysis. This analysis can further be used to do customer segmentation and track metrics like retention, churn, and lifetime value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQ62QseViqa2"
   },
   "source": [
    "# #Project Structures\n",
    "\n",
    "- Data Cleaning & Exploratory Data Analysis\n",
    "- RFM Analysis\n",
    "- Customer Segmentation\n",
    "- Applying K-Means Clustering\n",
    "- Create Cohort and Conduct Cohort Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsPQ1tUwiqa2"
   },
   "source": [
    "# #Tasks\n",
    "\n",
    "#### 1. Data Cleaning & Exploratory Data Analysis\n",
    "\n",
    "- Import Modules, Load Data & Data Review\n",
    "- Follow the Steps Below\n",
    "\n",
    "    *i. Take a look at relationships between InvoiceNo, Quantity and UnitPrice columns.*\n",
    "    \n",
    "    *ii. What does the letter \"C\" in the invoiceno column mean?*\n",
    "    \n",
    "    *iii. Handling Missing Values*\n",
    "    \n",
    "    *iv. Clean the Data from the Noise and Missing Values*\n",
    "    \n",
    "    *v. Explore the Orders*\n",
    "    \n",
    "    *vi. Explore Customers by Country*\n",
    "    \n",
    "    *vii. Explore the UK Market*\n",
    "    \n",
    "#### 2. RFM Analysis\n",
    "\n",
    "- Follow the steps below\n",
    "\n",
    "   *i. Import Libraries*\n",
    "   \n",
    "   *ii. Review \"df_uk\" DataFrame (the df_uk what you create at the end of the Task 1)*\n",
    "   \n",
    "   *iii. Calculate Recency*\n",
    "   \n",
    "   *iv. Calculate Frequency*\n",
    "   \n",
    "   *v. Calculate Monetary Values*\n",
    "   \n",
    "   *vi. Create RFM Table*\n",
    "\n",
    "#### 3. Customer Segmentation with RFM Scores\n",
    "- Calculate RFM Scoring\n",
    "\n",
    "    *i. Creating the RFM Segmentation Table*\n",
    " \n",
    "- Plot RFM Segments\n",
    "\n",
    "#### 4. Applying K-Means Clustering\n",
    "- Data Pre-Processing and Exploring\n",
    "\n",
    "    *i. Define and Plot Feature Correlations*\n",
    " \n",
    "    *ii. Visualize Feature Distributions*\n",
    " \n",
    "    *iii. Data Normalization*\n",
    "\n",
    "- K-Means Implementation\n",
    "\n",
    "    *i. Define Optimal Cluster Number (K) by using \"Elbow Method\" and \"Silhouette Analysis\"*\n",
    " \n",
    "    *ii. Visualize the Clusters*\n",
    " \n",
    "    *iii. Assign the label*\n",
    " \n",
    "    *iv. Conclusion*\n",
    " \n",
    "#### 5. Create Cohort and Conduct Cohort Analysis\n",
    "- Future Engineering\n",
    "\n",
    "    *i. Extract the Month of the Purchase*\n",
    " \n",
    "    *ii. Calculating time offset in Months i.e. Cohort Index*\n",
    " \n",
    "- Create 1st Cohort: User Number & Retention Rate \n",
    "\n",
    "    *i. Pivot Cohort and Cohort Retention*\n",
    " \n",
    "    *ii. Visualize analysis of cohort 1 using seaborn and matplotlib*\n",
    "\n",
    "- Create 2nd Cohort: Average Quantity Sold \n",
    "\n",
    "    *i. Pivot Cohort and Cohort Retention*\n",
    " \n",
    "    *ii. Visualize analysis of cohort 2 using seaborn and matplotlib*\n",
    "\n",
    "- Create 3rd Cohort: Average Sales\n",
    "\n",
    "    *i. Pivot Cohort and Cohort Retention*\n",
    " \n",
    "    *ii. Visualize analysis of cohort 3 using seaborn and matplotlib*\n",
    "    \n",
    "- **Note: There may be sub-tasks associated with each task, you will see them in order during the course of the work.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-NlVU1UQGVA"
   },
   "source": [
    "# 1. Data Cleaning & Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L63G_-Dqiqa3"
   },
   "source": [
    "## Import Modules, Load Data & Data Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting squarify\n",
      "  Downloading squarify-0.4.3-py3-none-any.whl (4.3 kB)\n",
      "Installing collected packages: squarify\n",
      "Successfully installed squarify-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "J-Zb5JfOiqa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install pyforest\n",
    "# 1-Import Libraies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import squarify as sq\n",
    "from termcolor import cprint\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import missingno as msno \n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PowerTransformer \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "# Importing plotly and cufflinks in offline mode\n",
    "import plotly.express as px\n",
    "import cufflinks as cf\n",
    "import plotly.offline\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "# !pip install termcolor\n",
    "import colorama\n",
    "from colorama import Fore, Style  # maakes strings colored\n",
    "from termcolor import colored\n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"this will not show\")\n",
    "\n",
    "# Figure&Display options\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "pd.set_option('max_colwidth',200)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view summary information about the df\n",
    "\n",
    "def first_looking(df):\n",
    "    print(colored(\"Shape:\", attrs=['bold']), df.shape,'\\n', \n",
    "          colored('-'*79, 'red', attrs=['bold']),\n",
    "          colored(\"\\nInfo:\\n\", attrs=['bold']), sep='')\n",
    "    print(df.info(), '\\n', \n",
    "          colored('-'*79, 'red', attrs=['bold']), sep='')\n",
    "    print(colored(\"Number of Uniques:\\n\", attrs=['bold']), df.nunique(),'\\n',\n",
    "          colored('-'*79, 'red', attrs=['bold']), sep='')\n",
    "    print(colored(\"Missing Values:\\n\", attrs=['bold']), missing_values(df),'\\n', \n",
    "          colored('-'*79, 'red', attrs=['bold']), sep='')\n",
    "    print(colored(\"All Columns:\", attrs=['bold']), list(df.columns),'\\n', \n",
    "          colored('-'*79, 'red', attrs=['bold']), sep='')\n",
    "\n",
    "    df.columns= df.columns.str.lower().str.replace('&', '_').str.replace(' ', '_')\n",
    "\n",
    "    print(colored(\"Columns after rename:\", attrs=['bold']), list(df.columns),'\\n',\n",
    "              colored('-'*79, 'red', attrs=['bold']), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view summary information about the columns\n",
    "\n",
    "def first_look(col):\n",
    "    print(\"column name    : \", col)\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"per_of_nulls   : \", \"%\", round(df[col].isnull().sum()/df.shape[0]*100, 2))\n",
    "    print(\"num_of_nulls   : \", df[col].isnull().sum())\n",
    "    print(\"num_of_uniques : \", df[col].nunique())\n",
    "    print(df[col].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the missing value information of df\n",
    "\n",
    "def missing_values(df):\n",
    "    missing_number = df.isnull().sum().sort_values(ascending=False)\n",
    "    missing_percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "    missing_values = pd.concat([missing_number, missing_percent], axis=1, keys=['Missing_Number', 'Missing_Percent'])\n",
    "    return missing_values[missing_values['Missing_Number']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some Useful Functions\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def missing_values(df):\n",
    "    missing_number = df.isnull().sum().sort_values(ascending=False)\n",
    "    missing_percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "    missing_values = pd.concat([missing_number, missing_percent], axis=1, keys=['Missing_Number', 'Missing_Percent'])\n",
    "    return missing_values[missing_values['Missing_Number']>0]\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def first_looking(df):\n",
    "    print(colored(\"Shape:\", attrs=['bold']), df.shape,'\\n', \n",
    "          colored('-'*79, 'red', attrs=['bold']),\n",
    "          colored(\"\\nInfo:\\n\", attrs=['bold']), sep='')\n",
    "    print(df.info(), '\\n', \n",
    "          colored('-'*79, 'red', attrs=['bold']), sep='')\n",
    "    print(colored(\"Number of Uniques:\\n\", attrs=['bold']), df.nunique(),'\\n',\n",
    "          colored('-'*79, 'red', attrs=['bold']), sep='')\n",
    "    print(colored(\"Missing Values:\\n\", attrs=['bold']), missing_values(df),'\\n', \n",
    "          colored('-'*79, 'red', attrs=['bold']), sep='')\n",
    "    print(colored(\"All Columns:\", attrs=['bold']), list(df.columns),'\\n', \n",
    "          colored('-'*79, 'red', attrs=['bold']), sep='')\n",
    "\n",
    "    df.columns= df.columns.str.lower().str.replace('&', '_').str.replace(' ', '_')\n",
    "\n",
    "    print(colored(\"Columns after rename:\", attrs=['bold']), list(df.columns),'\\n',\n",
    "              colored('-'*79, 'red', attrs=['bold']), sep='')\n",
    "    \n",
    "        \n",
    "def multicolinearity_control(df):\n",
    "    feature =[]\n",
    "    collinear=[]\n",
    "    for col in df.corr().columns:\n",
    "        for i in df.corr().index:\n",
    "            if (abs(df.corr()[col][i])> .9 and abs(df.corr()[col][i]) < 1):\n",
    "                    feature.append(col)\n",
    "                    collinear.append(i)\n",
    "                    print(colored(f\"Multicolinearity alert in between:{col} - {i}\", \n",
    "                                  \"red\", attrs=['bold']), df.shape,'\\n',\n",
    "                                  colored('-'*79, 'red', attrs=['bold']), sep='')\n",
    "\n",
    "def duplicate_values(df):\n",
    "    print(colored(\"Duplicate check...\", attrs=['bold']), sep='')\n",
    "    duplicate_values = df.duplicated(subset=None, keep='first').sum()\n",
    "    if duplicate_values > 0:\n",
    "        df.drop_duplicates(keep='first', inplace=True)\n",
    "        print(duplicate_values, colored(\"Duplicates were dropped!\"),'\\n',\n",
    "              colored('-'*79, 'red', attrs=['bold']), sep='')\n",
    "    else:\n",
    "        print(colored(\"There are no duplicates\"),'\\n',\n",
    "              colored('-'*79, 'red', attrs=['bold']), sep='')     \n",
    "        \n",
    "def drop_columns(df, drop_columns):\n",
    "    if drop_columns !=[]:\n",
    "        df.drop(drop_columns, axis=1, inplace=True)\n",
    "        print(drop_columns, 'were dropped')\n",
    "    else:\n",
    "        print(colored('We will now check the missing values and if necessary will drop related columns!', attrs=['bold']),'\\n',\n",
    "              colored('-'*79, 'red', attrs=['bold']), sep='')\n",
    "        \n",
    "def drop_null(df, limit):\n",
    "    print('Shape:', df.shape)\n",
    "    for i in df.isnull().sum().index:\n",
    "        if (df.isnull().sum()[i]/df.shape[0]*100)>limit:\n",
    "            print(df.isnull().sum()[i], 'percent of', i ,'null and were dropped')\n",
    "            df.drop(i, axis=1, inplace=True)\n",
    "            print('new shape:', df.shape)       \n",
    "    print('New shape after missing value control:', df.shape)\n",
    "        \n",
    "###############################################################################\n",
    "\n",
    "# To view summary information about the column\n",
    "\n",
    "def first_look(col):\n",
    "    print(\"column name    : \", col)\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"per_of_nulls   : \", \"%\", round(df[col].isnull().sum()/df.shape[0]*100, 2))\n",
    "    print(\"num_of_nulls   : \", df[col].isnull().sum())\n",
    "    print(\"num_of_uniques : \", df[col].nunique())\n",
    "    print(df[col].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Online Retail.xlsx\", header=0)\n",
    "\n",
    "# rfm_single_view=pd.read_csv('RFM Data.csv')\n",
    "# rfm_single_view.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365.0</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365.0</td>\n",
       "      <td>71053.0</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365.0</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365.0</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365.0</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0  536365.0    85123A   WHITE HANGING HEART T-LIGHT HOLDER       6.0   \n",
       "1  536365.0   71053.0                  WHITE METAL LANTERN       6.0   \n",
       "2  536365.0    84406B       CREAM CUPID HEARTS COAT HANGER       8.0   \n",
       "3  536365.0    84029G  KNITTED UNION FLAG HOT WATER BOTTLE       6.0   \n",
       "4  536365.0    84029E       RED WOOLLY HOTTIE WHITE HEART.       6.0   \n",
       "\n",
       "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
       "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
       "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541904</th>\n",
       "      <td>581587.0</td>\n",
       "      <td>22613.0</td>\n",
       "      <td>PACK OF 20 SPACEBOY NAPKINS</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12680.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541905</th>\n",
       "      <td>581587.0</td>\n",
       "      <td>22899.0</td>\n",
       "      <td>CHILDREN'S APRON DOLLY GIRL</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>12680.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541906</th>\n",
       "      <td>581587.0</td>\n",
       "      <td>23254.0</td>\n",
       "      <td>CHILDRENS CUTLERY DOLLY GIRL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>12680.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541907</th>\n",
       "      <td>581587.0</td>\n",
       "      <td>23255.0</td>\n",
       "      <td>CHILDRENS CUTLERY CIRCUS PARADE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>12680.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541908</th>\n",
       "      <td>581587.0</td>\n",
       "      <td>22138.0</td>\n",
       "      <td>BAKING SET 9 PIECE RETROSPOT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>4.95</td>\n",
       "      <td>12680.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo StockCode                      Description  Quantity  \\\n",
       "541904  581587.0   22613.0      PACK OF 20 SPACEBOY NAPKINS      12.0   \n",
       "541905  581587.0   22899.0     CHILDREN'S APRON DOLLY GIRL        6.0   \n",
       "541906  581587.0   23254.0    CHILDRENS CUTLERY DOLLY GIRL        4.0   \n",
       "541907  581587.0   23255.0  CHILDRENS CUTLERY CIRCUS PARADE       4.0   \n",
       "541908  581587.0   22138.0    BAKING SET 9 PIECE RETROSPOT        3.0   \n",
       "\n",
       "               InvoiceDate  UnitPrice  CustomerID Country  \n",
       "541904 2011-12-09 12:50:00       0.85     12680.0  France  \n",
       "541905 2011-12-09 12:50:00       2.10     12680.0  France  \n",
       "541906 2011-12-09 12:50:00       4.15     12680.0  France  \n",
       "541907 2011-12-09 12:50:00       4.15     12680.0  France  \n",
       "541908 2011-12-09 12:50:00       4.95     12680.0  France  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235911</th>\n",
       "      <td>C557658</td>\n",
       "      <td>84946.0</td>\n",
       "      <td>ANTIQUE SILVER T-LIGHT GLASS</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2011-06-21 17:41:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>13630.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224717</th>\n",
       "      <td>556573.0</td>\n",
       "      <td>21621.0</td>\n",
       "      <td>VINTAGE UNION JACK BUNTING</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2011-06-13 13:32:00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>14667.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260642</th>\n",
       "      <td>559816.0</td>\n",
       "      <td>21802.0</td>\n",
       "      <td>CHRISTMAS TREE HEART DECORATION</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-07-12 16:11:00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305442</th>\n",
       "      <td>563691.0</td>\n",
       "      <td>22154.0</td>\n",
       "      <td>ANGEL DECORATION 3 BUTTONS</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2011-08-18 12:53:00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>13668.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199207</th>\n",
       "      <td>554089.0</td>\n",
       "      <td>22778.0</td>\n",
       "      <td>GLASS CLOCHE SMALL</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2011-05-22 12:16:00</td>\n",
       "      <td>3.95</td>\n",
       "      <td>13527.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo StockCode                      Description  Quantity  \\\n",
       "235911   C557658   84946.0     ANTIQUE SILVER T-LIGHT GLASS      -1.0   \n",
       "224717  556573.0   21621.0       VINTAGE UNION JACK BUNTING       6.0   \n",
       "260642  559816.0   21802.0  CHRISTMAS TREE HEART DECORATION       1.0   \n",
       "305442  563691.0   22154.0      ANGEL DECORATION 3 BUTTONS       48.0   \n",
       "199207  554089.0   22778.0               GLASS CLOCHE SMALL       3.0   \n",
       "\n",
       "               InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "235911 2011-06-21 17:41:00       1.25     13630.0  United Kingdom  \n",
       "224717 2011-06-13 13:32:00       8.50     14667.0  United Kingdom  \n",
       "260642 2011-07-12 16:11:00       0.42         NaN  United Kingdom  \n",
       "305442 2011-08-18 12:53:00       0.42     13668.0  United Kingdom  \n",
       "199207 2011-05-22 12:16:00       3.95     13527.0  United Kingdom  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape:\u001b[0m(541909, 8)\n",
      "\u001b[1m\u001b[31m-------------------------------------------------------------------------------\u001b[0m\u001b[1m\n",
      "Info:\n",
      "\u001b[0m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InvoiceNo    541909 non-null  object        \n",
      " 1   StockCode    541909 non-null  object        \n",
      " 2   Description  540455 non-null  object        \n",
      " 3   Quantity     541909 non-null  float64       \n",
      " 4   InvoiceDate  541909 non-null  datetime64[ns]\n",
      " 5   UnitPrice    541909 non-null  float64       \n",
      " 6   CustomerID   406829 non-null  float64       \n",
      " 7   Country      541909 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(4)\n",
      "memory usage: 33.1+ MB\n",
      "None\n",
      "\u001b[1m\u001b[31m-------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1mNumber of Uniques:\n",
      "\u001b[0mInvoiceNo      25900\n",
      "StockCode       4070\n",
      "Description     4223\n",
      "Quantity         722\n",
      "InvoiceDate    23260\n",
      "UnitPrice       1630\n",
      "CustomerID      4372\n",
      "Country           38\n",
      "dtype: int64\n",
      "\u001b[1m\u001b[31m-------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1mMissing Values:\n",
      "\u001b[0m             Missing_Number  Missing_Percent\n",
      "CustomerID           135080            0.249\n",
      "Description            1454            0.003\n",
      "\u001b[1m\u001b[31m-------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1mAll Columns:\u001b[0m['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']\n",
      "\u001b[1m\u001b[31m-------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1mColumns after rename:\u001b[0m['invoiceno', 'stockcode', 'description', 'quantity', 'invoicedate', 'unitprice', 'customerid', 'country']\n",
      "\u001b[1m\u001b[31m-------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "first_looking(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>quantity</th>\n",
       "      <td>541909.000</td>\n",
       "      <td>9.552</td>\n",
       "      <td>218.081</td>\n",
       "      <td>-80995.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>80995.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unitprice</th>\n",
       "      <td>541909.000</td>\n",
       "      <td>4.611</td>\n",
       "      <td>96.760</td>\n",
       "      <td>-11062.060</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.080</td>\n",
       "      <td>4.130</td>\n",
       "      <td>38970.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerid</th>\n",
       "      <td>406829.000</td>\n",
       "      <td>15287.691</td>\n",
       "      <td>1713.600</td>\n",
       "      <td>12346.000</td>\n",
       "      <td>13953.000</td>\n",
       "      <td>15152.000</td>\n",
       "      <td>16791.000</td>\n",
       "      <td>18287.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count      mean      std        min       25%       50%  \\\n",
       "quantity   541909.000     9.552  218.081 -80995.000     1.000     3.000   \n",
       "unitprice  541909.000     4.611   96.760 -11062.060     1.250     2.080   \n",
       "customerid 406829.000 15287.691 1713.600  12346.000 13953.000 15152.000   \n",
       "\n",
       "                 75%       max  \n",
       "quantity      10.000 80995.000  \n",
       "unitprice      4.130 38970.000  \n",
       "customerid 16791.000 18287.000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>invoiceno</th>\n",
       "      <td>541909.000</td>\n",
       "      <td>25900.000</td>\n",
       "      <td>573585.000</td>\n",
       "      <td>1114.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stockcode</th>\n",
       "      <td>541909</td>\n",
       "      <td>4070</td>\n",
       "      <td>85123A</td>\n",
       "      <td>2313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>540455</td>\n",
       "      <td>4223</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>2369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>541909</td>\n",
       "      <td>38</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>495478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count    unique                                 top     freq\n",
       "invoiceno   541909.000 25900.000                          573585.000 1114.000\n",
       "stockcode       541909      4070                              85123A     2313\n",
       "description     540455      4223  WHITE HANGING HEART T-LIGHT HOLDER     2369\n",
       "country         541909        38                      United Kingdom   495478"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=object).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5268 duplicated observations in the dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", df.duplicated(subset=None, keep='first').sum(), \"duplicated observations in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YECMxCzUQGV7"
   },
   "source": [
    "### i. Take a look at relationships between InvoiceNo, Quantity and UnitPrice columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQ8vAKbbiqa4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiSW67N_QGV8"
   },
   "source": [
    "We see that there are negative values in the Quantity and UnitPrice columns. These are possibly canceled and returned orders. Let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZoHopX7-iqa4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OoPE-QLiqa4"
   },
   "source": [
    "### ii. What does the letter \"C\" in the InvoiceNo column mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PgN0C80Giqa5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kt32SZgJQGV8"
   },
   "source": [
    "If the invoice number starts with the letter \"C\", it means the order was cancelled. Or those who abandon their order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-sdD1F4Xiqa5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YP5RPZq1QGV_"
   },
   "source": [
    "When we filter canceled orders by Quantity> 0 or filter non-canceled orders by Quantity <0 nothing returns, this confirms that negative values mean the order was canceled. So lets find out how many orders were cancelled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxrhRFHhiqa5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrp8logRQGWA"
   },
   "source": [
    "#### 9288 or about 36% of the orders were cancelled. Looking deeper into why these orders were cancelled may prevent future cancellations. Now let's find out what a negative UnitPrice means.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1OI-xuxxiqa5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXVVls6sQGVQ"
   },
   "source": [
    "### iii. Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yExVxnQsiqa6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQtZK5paQGVf"
   },
   "source": [
    "Since the customer ID's are missing, lets assume these orders were not made by the customers already in the data set because those customers already have ID's. \n",
    "\n",
    "We also don't want to assign these orders to those customers because this would alter the insights we draw from the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WjvtekM3iqa6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llu-bMTAiqa6"
   },
   "source": [
    "### iv. Clean the Data from the Noise and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-TgtE4Ziqa6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25MkNjZqQGWC"
   },
   "source": [
    "### v. Explore the Orders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OAkPoUjiqa7"
   },
   "source": [
    "1. Find the unique number of InvoiceNo  per customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1A76M7Jiqa7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "di03OKjzQGWE"
   },
   "source": [
    "2. What's the average number of unqiue items per order or per customer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4LxkeIIiqa7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUKzA73dQGWH"
   },
   "source": [
    "3. Let's see how this compares to the number of unique products per customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8uzjYyKiqa7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_Ozp-U5QGWK"
   },
   "source": [
    "### vi. Explore Customers by Country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SP6M3isLiqa8"
   },
   "source": [
    "1. What's the total revenue per country?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VISxZ3Ixiqa8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qk64qtEliqa8"
   },
   "source": [
    "2. Visualize number of customer per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atuYU8W2iqa8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TD66fT3iqa8"
   },
   "source": [
    "3. Visualize total cost per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5i0nVOggiqa8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwfJuBVCQGWR"
   },
   "source": [
    "#### The UK not only has the most sales revenue, but also the most customers. Since the majority of this data set contains orders from the UK, we can explore the UK market further by finding out what products the customers buy together and any other buying behaviors to improve our sales and targeting strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LlyhW9eXiqa9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7A25nnqIQGWR"
   },
   "source": [
    "### vii. Explore the UK Market\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtWchB1Ziqa9"
   },
   "source": [
    "1. Create df_uk DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dsdH3cuZiqa9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "is5kus2bQGWT"
   },
   "source": [
    "2. What are the most popular products that are bought in the UK?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCN56amLiqa9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHbqJD7bQGWU"
   },
   "source": [
    "### We will continue analyzing the UK transactions with customer segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAtzWvugQGWV"
   },
   "source": [
    "# 2. RFM Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5uUAUQpQGWV"
   },
   "source": [
    "In the age of the internet and e-commerce, companies that do not expand their businesses online or utilize digital tools to reach their customers will run into issues like scalability and a lack of digital precsence. An important marketing strategy e-commerce businesses use for analyzing and predicting customer value is customer segmentation. Customer data is used to sort customers into group based on their behaviors and preferences.\n",
    "\n",
    "**[RFM](https://www.putler.com/rfm-analysis/) (Recency, Frequency, Monetary) Analysis** is a customer segmentation technique for analyzing customer value based on past buying behavior. RFM analysis was first used by the direct mail industry more than four decades ago, yet it is still an effective way to optimize your marketing.\n",
    "<br>\n",
    "<br>\n",
    "Our goal in this Notebook is to cluster the customers in our data set to:\n",
    " - Recognize who are our most valuable customers\n",
    " - Increase revenue\n",
    " - Increase customer retention\n",
    " - Learn more about the trends and behaviors of our customers\n",
    " - Define customers that are at risk\n",
    "\n",
    "We will start with **RFM Analysis** and then compliment our findings with predictive analysis using **K-Means Clustering Algorithms.**\n",
    "\n",
    "- RECENCY (R): Time since last purchase\n",
    "- FREQUENCY (F): Total number of purchases\n",
    "- MONETARY VALUE (M): Total monetary value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Benefits of RFM Analysis\n",
    "\n",
    "- Increased customer retention\n",
    "- Increased response rate\n",
    "- Increased conversion rate\n",
    "- Increased revenue\n",
    "\n",
    "RFM Analysis answers the following questions:\n",
    " - Who are our best customers?\n",
    " - Who has the potential to be converted into more profitable customers?\n",
    " - Which customers do we need to retain?\n",
    " - Which group of customers is most likely to respond to our marketing campaign?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zX47_J8OQGWV"
   },
   "source": [
    "### i. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOD15BxHiqa-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rYM4MJsQGWW"
   },
   "source": [
    "### ii. Review df_uk DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQHyAJNeiqa-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvfCcPLgQGWa"
   },
   "source": [
    "### iii. Recency: Days since last purchase\n",
    "To calculate the recency values, follow these steps in order:\n",
    "\n",
    "1. To calculate recency, we need to choose a date as a point of reference to evaluate how many days ago was the customer's last purchase.\n",
    "2. Create a new column called Date which contains the invoice date without the timestamp\n",
    "3. Group by CustomerID and check the last date of purchase\n",
    "4. Calculate the days since last purchase\n",
    "5. Drop Last_Purchase_Date since we don't need it anymore\n",
    "6. Plot RFM distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7Gzn6r6QGWb"
   },
   "source": [
    "1. Choose a date as a point of reference to evaluate how many days ago was the customer's last purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwWODVSZiqa-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ge34PCT0iqa-"
   },
   "source": [
    "2. Create a new column called Date which contains the invoice date without the timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsaFUydXiqa_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KJzP5Ldiqa_"
   },
   "source": [
    "3. Group by CustomerID and check the last date of purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8kMt-Uyiqa_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Zxs1mzPiqa_"
   },
   "source": [
    "4. Calculate the days since last purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTeKws6giqa_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAuMSkfsiqa_"
   },
   "source": [
    "5. Drop Last_Purchase_Date since we don't need it anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bNmKqHNiqa_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IB9a0AL9iqa_"
   },
   "source": [
    "6. Plot RFM distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8e-QiwRiqa_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAjKZD0KQGWg"
   },
   "source": [
    "### iv. Frequency: Number of purchases\n",
    "\n",
    "To calculate how many times a customer purchased something, we need to count how many invoices each customer has. To calculate the frequency values, follow these steps in order:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDoNslseiqbA"
   },
   "source": [
    "1. Make a copy of df_uk and drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gk2gokFiqbA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KrnuXrLiqbA"
   },
   "source": [
    "2. Calculate the frequency of purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LTM_cxpiqbA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9NNBCNgiqbA"
   },
   "source": [
    "3. Plot RFM distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUtZAHu1iqbA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUY3gKjQQGWh"
   },
   "source": [
    "### v. Monetary: Total amount of money spent\n",
    "\n",
    "The monetary value is calculated by adding together the cost of the customers' purchases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_4_QLWtiqbA"
   },
   "source": [
    "1. Calculate sum total cost by customers and named \"Monetary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bilKBqvIiqbB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYsaCPRDiqbB"
   },
   "source": [
    "2. Plot RFM distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sd41fD67iqbB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeaecPkSQGWj"
   },
   "source": [
    "### vi. Create RFM Table\n",
    "Merge the recency, frequency and motetary dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M88KNSbyiqbB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULWwsxCkQGWl"
   },
   "source": [
    "# 3. Customer Segmentation with RFM Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZrxUBX4iqbB"
   },
   "source": [
    "Businesses have this ever-lasting urge to understand their customers. The better you understand the customer, the better you serve them, and the higher the financial gain you receive from that customer. Since the dawn of trade, this process of understanding customers for a strategic gain has been there practiced and this task is known majorly as [Customer Segmentation](https://clevertap.com/blog/rfm-analysis/).\n",
    "Well as the name suggests, Customer Segmentation could segment customers according to their precise needs. Some of the common ways of segmenting customers are based on their Recency-Frequency-Monatory values, their demographics like gender, region, country, etc, and some of their business-crafted scores. You will use Recency-Frequency-Monatory values for this case.\n",
    "\n",
    "In this section, you will create an RFM Segmentation Table where you segment your customers by using the RFM table. For example, you can label the best customer as \"Big Spenders\" and the lost customer as \"Lost Customer\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anOsOGpfQGWl"
   },
   "source": [
    "## Calculate RFM Scoring\n",
    "\n",
    "The simplest way to create customer segments from an RFM model is by using **Quartiles**. We will assign a score from 1 to 4 to each category (Recency, Frequency, and Monetary) with 4 being the highest/best value. The final RFM score is calculated by combining all RFM values. For Customer Segmentation, you will use the df_rfm data set resulting from the RFM analysis.\n",
    "<br>\n",
    "<br>\n",
    "**Note**: Data can be assigned into more groups for better granularity, but we will use 4 in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiwXSsP7iqbB"
   },
   "source": [
    "1. Divide the df_rfm into quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFQJGPYHiqbC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnkzCAf9QGWo"
   },
   "source": [
    "### i. Creating the RFM Segmentation Table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLIB-z-_iqbC"
   },
   "source": [
    "1. Create two functions, one for Recency and one for Frequency and Monetary. For Recency, customers in the first quarter should be scored as 4, this represents the highest Recency value. Conversely, for Frequency and Monetary, customers in the last quarter should be scored as 4, representing the highest Frequency and Monetary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXnW03R8iqbC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLDK_XeLiqbC"
   },
   "source": [
    "2. Score customers from 1 to 4 by applying the functions you have created. Also create separate score column for each value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plReZMcQiqbC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JskteCFdQGWq"
   },
   "source": [
    "3. Now that scored each customer, you'll combine the scores for segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYfoHF6QiqbC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWwWeyjPiqbC"
   },
   "source": [
    "4. Define rfm_level function that tags customers by using RFM_Scrores and Create a new variable RFM_Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxXk7jFPiqbD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lq36PiX3iqbD"
   },
   "source": [
    "5. Calculate average values for each RFM_Level, and return a size of each segment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jn5r5P2WiqbD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuZ5Olo4iqbD"
   },
   "source": [
    "## Plot RFM Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STfELckwiqbD"
   },
   "source": [
    "1. Create your plot and resize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oef37q3diqbD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhOe2bb6QGWu"
   },
   "source": [
    "Using customer segmentation categories found [here](http://www.blastam.com/blog/rfm-analysis-boosts-sales) we can formulate different marketing strategies and approaches for customer engagement for each type of customer.\n",
    "\n",
    "Note: The author in the article scores 1 as the highest and 4 as the lowest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Te_6gUR5iqbD"
   },
   "source": [
    "2. How many customers do we have in each segment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gs4rP-0viqbD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RwemvLyQGWv"
   },
   "source": [
    "# 3. Applying K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6WZ0PnZQGWv"
   },
   "source": [
    "Now that we have our customers segmented into 6 different categories, we can gain further insight into customer behavior by using predictive models in conjuction with out RFM model.\n",
    "Possible algorithms include **Logistic Regression**, **K-means Clustering**, and **K-nearest Neighbor**. We will go with [K-Means](https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1) since we already have our distinct groups determined. K-means has also been widely used for market segmentation and has the advantage of being simple to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrWIRLkMiqbE"
   },
   "source": [
    "## Data Pre-Processing and Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLoRGR6NiqbE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6SGV0xoQGWw"
   },
   "source": [
    "### i. Define and Plot Feature Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpMAiWNBiqbE"
   },
   "source": [
    "Create Heatmap and evaluate the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6Cv8_EqiqbE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WhL5MBEQGWy"
   },
   "source": [
    "### ii. Visualize Feature Distributions\n",
    "\n",
    "To get a better understanding of the dataset, you can costruct a scatter matrix of each of the three features in the RFM data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHE0Vb0KiqbE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2RsjzjbQGWz"
   },
   "source": [
    "### iii. Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXsrPpegiqbF"
   },
   "source": [
    "1. You can use the logarithm method to normalize the values in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-cBU8jxiqbF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC6dHnqKiqbF"
   },
   "source": [
    "2. Plot normalized data with scatter matrix or pairplot. Also evaluate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iB9jDUPriqbF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35c0aDixQGW4"
   },
   "source": [
    "## K-Means Implementation\n",
    "\n",
    "For k-means, you have to set k to the number of clusters you want, but figuring out how many clusters is not obvious from the beginning. We will try different cluster numbers and check their [silhouette coefficient](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html). The silhouette coefficient for a data point measures how similar it is to its assigned cluster from -1 (dissimilar) to 1 (similar). \n",
    "<br>\n",
    "<br>\n",
    "**Note**: K-means is sensitive to initializations because they are critical to qualifty of optima found. Thus, we will use smart initialization called \"Elbow Method\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JloMSEeriqbF"
   },
   "source": [
    "### i. Define the Optimal Number of Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McFq6IWZt5hg"
   },
   "source": [
    "[The Elbow Method](https://en.wikipedia.org/wiki/Elbow_method_(clustering) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2202eo2riqbF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACT_d0UpwUSC"
   },
   "source": [
    "[Silhouette Coefficient](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qS4TLbRniqbG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6dW2MWZiqbG"
   },
   "source": [
    "### ii. Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXM5ksoPiqbG"
   },
   "source": [
    "Fit the K-Means Algorithm with the optimal number of clusters you decided and save the model to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geMuViLniqbG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqcSwNZTQGW7"
   },
   "source": [
    "### iii. Visualize the Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cfx5kzPriqbG"
   },
   "source": [
    "1. Create a scatter plot and select cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyrovJB0iqbH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4sHOvlniqbH"
   },
   "source": [
    "2. Visualize Cluster Id vs Recency, Cluster Id vs Frequency and Cluster Id vs Monetary using Box plot. Also evaluate the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzPl-LXViqbH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRyku5qJiqbH"
   },
   "source": [
    "### iv. Assign the Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVrkisf9iqbH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DiG6sxS4gWH"
   },
   "source": [
    "**Conclusion**\n",
    "\n",
    "- Cluster 0 : The first cluster belongs to the \"Best Customers\" segment which we saw earlier as they purchase recently (R=4), frequent buyers (F=4), and spent the most (M=4)\n",
    "\n",
    "- Cluster 1 : Second cluster can be interpreted as passer customers as their last purchase is long ago (R<=1),purchased very few (F>=2 & F < 4) and spent little (M>=4 & M < 4).Company has to come up with new strategies to make them permanent members. Low value customers\n",
    "- Cluster 2 : The third cluster is more related to the \"Almost Lost\" segment as they Havent purchased for some time(R=1), but used to purchase frequently and spent a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lf4OsPmSQGXA"
   },
   "source": [
    "### v. Conclusion\n",
    "\n",
    "Discuss your final results. Compare your own labels from the Customer Segmentation with the labels found by K-Means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFaHgoLoQGXA"
   },
   "source": [
    "How we want to continue this analysis depends on how the business plans to use the results and the level of granularity the business stakeholders want to see in the clusters. We can also ask what range of customer behavior from high to low value customers are the stakeholders interested in exploring. From those answers, various methods of clustering can be used and applied on RFM variable or directly on the transaction data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysCkU1B-iqbI"
   },
   "source": [
    "**Annotation:**\n",
    "\n",
    "Limitations of K-means clustering:\n",
    "\n",
    "1. There is no assurance that it will lead to the global best solution.\n",
    "2. Can't deal with different shapes(not circular) and consider one point's probability of belonging to more than one cluster.\n",
    "\n",
    "These disadvantages of K-means show that for many datasets (especially low-dimensional datasets), it may not perform as well as you might hope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiPd_IbnQGVn"
   },
   "source": [
    "# 5. Create Cohort & Conduct Cohort Analysis\n",
    "[Cohort Analysis](https://medium.com/swlh/cohort-analysis-using-python-and-pandas-d2a60f4d0a4d) is specifically useful in analyzing user growth patterns for products. In terms of a product, a cohort can be a group of people with the same sign-up date, the same usage starts month/date, or the same traffic source.\n",
    "Cohort analysis is an analytics method by which these groups can be tracked over time for finding key insights. This analysis can further be used to do customer segmentation and track metrics like retention, churn, and lifetime value.\n",
    "\n",
    "For e-commerce organizations, cohort analysis is a unique opportunity to find out which clients are the most valuable to their business. by performing Cohort analysis you can get the following answers to the following questions:\n",
    "\n",
    "- How much effective was a marketing campaign held in a particular time period?\n",
    "- Did the strategy employ to improve the conversion rates of Customers worked?\n",
    "- Should I focus more on retention rather than acquiring new customers?\n",
    "- Are my customer nurturing strategies effective?\n",
    "- Which marketing channels bring me the best results?\n",
    "- Is there a seasonality pattern in Customer behavior?\n",
    "- Along with various performance measures/metrics for your organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhiYivPrQGVo"
   },
   "source": [
    "Since we will be performing Cohort Analysis based on transaction records of customers, the columns we will be dealing with mainly:\n",
    "- Invoice Data\n",
    "- CustomerID\n",
    "- Price\n",
    "- Quantity\n",
    "\n",
    "The following steps will performed to generate the Cohort Chart of Retention Rate:\n",
    "- Month Extraction from InvioceDate column\n",
    "- Assigning Cohort to Each Transaction\n",
    "- Assigning Cohort Index to each transaction\n",
    "- Calculating number of unique customers in each Group of (ChortDate,Index)\n",
    "- Creating Cohort Table for Retention Rate\n",
    "- Creating the Cohort Chart using the Cohort Table\n",
    "\n",
    "The Detailed information about each step is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eo0GB_osiqbI"
   },
   "source": [
    "## Future Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVwPNjpyQGVo"
   },
   "source": [
    "### i. Extract the Month of the Purchase\n",
    "First we will create a function, which takes any date and returns the formatted date with day value as 1st of the same month and Year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lK1CqlNQiqbI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQKsM_9IQGVq"
   },
   "source": [
    "Now we will use the function created above to convert all the invoice dates into respective month date format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DL17u0dniqbJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPE7kTz2QGVs"
   },
   "source": [
    "### ii. Calculating time offset in Months i.e. Cohort Index:\n",
    "Calculating time offset for each transaction will allows us to report the metrics for each cohort in a comparable fashion.\n",
    "First, you will create 4 variables that capture the integer value of years, months for Invoice and Cohort Date using the get_date_int() function which you'll create it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_3aYf4FiqbJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGm1eweDQGVu"
   },
   "source": [
    "You will use this function to extract the integer values for Invoice as well as Cohort Date in 3 seperate series for each of the two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2wF_ViD_iqbJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9jYVljviqbJ"
   },
   "source": [
    "Use the variables created above to calcualte the difference in days and store them in cohort Index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVlAYCbEiqbJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-t76CXSQGVw"
   },
   "source": [
    "## Create 1st Cohort: User number & Retention Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKvUWci9iqbJ"
   },
   "source": [
    "### i. Pivot Cohort and Cohort Retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-8HzlZWiqbK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63TIyBY6iqbK"
   },
   "source": [
    "### ii. Visualize analysis of cohort 1 using seaborn and matplotlib modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SY7mPvCAiqbK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yORYolvqQGV0"
   },
   "source": [
    "## Create the 2nd Cohort: Average Quantity Sold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu1hM3CFiqbK"
   },
   "source": [
    "### i. Pivot Cohort and Cohort Retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQ8jlhPEiqbK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3PJHMS6iqbK"
   },
   "source": [
    "### ii. Visualize analysis of cohort 2 using seaborn and matplotlib modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vuHi3wPiqbK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUoG5yUIQGV3"
   },
   "source": [
    "## Create the 3rd Cohort: Average Sales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKNS-mO5iqbL"
   },
   "source": [
    "### i. Pivot Cohort and Cohort Retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2s-zyWeiqbL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRGOpeUPiqbL"
   },
   "source": [
    "### ii. Visualize analysis of cohort 3 using seaborn and matplotlib modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYkkDncXiqbL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uD9lu1ExQGV5"
   },
   "source": [
    "For e-commerce organisations, cohort analysis is a unique opportunity to find out which clients are the most valuable to their business. by performing Cohort analysis you can get answers to following questions:\n",
    "\n",
    "- How much effective was a marketing campaign held in a particular time period?\n",
    "- Did the strategy employed to improve the conversion rates of Customers worked?\n",
    "- Should I focus more on retention rather than acquiring new customers?\n",
    "- Are my customer nurturing strategies effective?\n",
    "- Which marketing channels bring me the best results?\n",
    "- Is there a seasoanlity pattern in Customer behahiour?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZX_Y6S36iqbL"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lf4OsPmSQGXA"
   ],
   "name": "RFM - Customer Segmentation_Student_V3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
